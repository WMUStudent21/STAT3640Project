{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hidden Markov Model\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from hmmlearn.hmm import MultinomialHMM\n",
    "from hmmlearn.vhmm import VariationalCategoricalHMM\n",
    "\n",
    "SEED = 42\n",
    "df = pd.read_csv('aggregated.csv')\n",
    "trend_data = df['nvidia'].values\n",
    "price_data = df['NVDA Monthly'].values\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct assumption Start Matrix\n",
    "\n",
    "states = ['Happy', 'Sad', 'Neutral']\n",
    "start_matrix = np.array([0.5, 0.3, 0.2])\n",
    "\n",
    "## UNIT TESTING\n",
    "assert np.sum(start_matrix) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 3 # states: happy, sad, neutral\n",
    "n_obs = 3 # observations: up, down, negligible change\n",
    "traintest_split = 0.7\n",
    "threshold = 0.07\n",
    "start_time, stop_time = 228, 242 # length of data: 242\n",
    "\n",
    "trend_data = trend_data[start_time:stop_time]\n",
    "price_data = price_data[start_time:stop_time]\n",
    "\n",
    "## Trend data: 0 - Happy, 1 - Sad, 2 - Neutral\n",
    "discrete_trend_data = [0 if x >= threshold else 1 if x <= -threshold else 2 for x in trend_data]\n",
    "## Price data: 0 - Up, 1 - Down, 2 - Negligible change\n",
    "discrete_price_data = [0 if x >= threshold else 1 if x <= -threshold else 2 for x in price_data]\n",
    "\n",
    "# Test and Train data\n",
    "trainTrend, testTrend = discrete_trend_data[:int(len(trend_data)*traintest_split)], discrete_trend_data[int(len(trend_data)*traintest_split):]\n",
    "trainPrice, discreteTestPrice = discrete_price_data[:int(len(price_data)*traintest_split)], discrete_price_data[int(len(price_data)*traintest_split):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition Matrix:\n",
      "            Happy       Sad   Neutral\n",
      "Happy    0.000000  0.333333  0.666667\n",
      "Sad      1.000000  0.000000  0.000000\n",
      "Neutral  0.333333  0.666667  0.000000\n"
     ]
    }
   ],
   "source": [
    "# Constructing the Transition Matrix\n",
    "\n",
    "# row is t, column is t+1\n",
    "symbolVocabTrend = {0: \"Happy\", 1: \"Sad\", 2: \"Neutral\"}\n",
    "\n",
    "# Construct count of transitions from one hidden state to another i.e how many times 0 becomes 1, 1 becomes 2 etc.\n",
    "transition_counts = {}\n",
    "for i in range(1, len(trainTrend)):\n",
    "    transition = (symbolVocabTrend[discrete_trend_data[i-1]], symbolVocabTrend[discrete_trend_data[i]])\n",
    "    if transition not in transition_counts:\n",
    "        transition_counts[transition] = 0\n",
    "    transition_counts[transition] += 1\n",
    "\n",
    "# print(transition_counts)\n",
    "\n",
    "# Construct the transition matrix from the counts\n",
    "transition_matrix = np.zeros((n_hidden, n_hidden))\n",
    "for i in range(n_hidden):\n",
    "    for j in range(n_hidden):\n",
    "        transition = (symbolVocabTrend[i], symbolVocabTrend[j])\n",
    "        if transition in transition_counts:\n",
    "            transition_matrix[i, j] = transition_counts[transition] / sum([value for key, value in transition_counts.items() if key[0] == symbolVocabTrend[i]])\n",
    "\n",
    "# Pretty print the transition matrix with row and column labels\n",
    "print(\"Transition Matrix:\")\n",
    "print(pd.DataFrame(transition_matrix, index=[\"Happy\", \"Sad\", \"Neutral\"], columns=[\"Happy\", \"Sad\", \"Neutral\"]))\n",
    "\n",
    "### UNIT TESTING ###\n",
    "\n",
    "# Test the transition matrix\n",
    "assert np.allclose(transition_matrix.sum(axis=1), np.ones(n_hidden)), \"Transition matrix rows should sum to 1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emission Matrix:\n",
      "               Up  Down  Negligible Change\n",
      "Happy    0.666667   0.0           0.333333\n",
      "Sad      0.666667   0.0           0.333333\n",
      "Neutral  0.666667   0.0           0.333333\n"
     ]
    }
   ],
   "source": [
    "# Building Price Emission Matrix\n",
    "\n",
    "# row is emitting column\n",
    "symbolVocabPrice = {0: \"Up\", 1: \"Down\", 2: \"Negligible Change\"}\n",
    "\n",
    "# Building Price Emission Matrix\n",
    "\n",
    "price_symbol_counts = {}\n",
    "\n",
    "# Iterate over the time series data of trend and price data along with the corresponding hidden states\n",
    "for trendState, priceAction in zip(trainTrend, trainPrice):\n",
    "    # Update symbol counts for price data\n",
    "    emission = (symbolVocabTrend[trendState], symbolVocabPrice[priceAction])\n",
    "    if emission not in price_symbol_counts:\n",
    "        price_symbol_counts[emission] = 0\n",
    "    price_symbol_counts[emission] += 1\n",
    "\n",
    "# print(price_symbol_counts)\n",
    "\n",
    "# Construct the emission matrix from the counts\n",
    "emission_matrix = np.zeros((n_hidden, n_obs))\n",
    "for i in range(n_hidden):\n",
    "    for j in range(n_obs):\n",
    "        emission = (symbolVocabTrend[i], symbolVocabPrice[j])\n",
    "        if emission in price_symbol_counts:\n",
    "            emission_matrix[i, j] = price_symbol_counts[emission] / sum([value for key, value in price_symbol_counts.items() if key[0] == symbolVocabTrend[i]])\n",
    "\n",
    "# Pretty print the emission matrix with row and column labels\n",
    "print(\"Emission Matrix:\")\n",
    "print(pd.DataFrame(emission_matrix, index=[\"Happy\", \"Sad\", \"Neutral\"], columns=[\"Up\", \"Down\", \"Negligible Change\"]))\n",
    "\n",
    "### UNIT TESTING ###\n",
    "\n",
    "# Test the emission matrix\n",
    "assert np.allclose(emission_matrix.sum(axis=1), np.ones(n_hidden)), \"Emission matrix rows should sum to 1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Markov Model\n",
    "Using Viterbi and Forward-Backward to decide states, we draft our plan as such: \\\n",
    "\n",
    "\n",
    "\n",
    "1. q_state = 3 { Happy, Sad, Neutral }\n",
    "\n",
    "2. obs_states = { Up, Down, Negligible Change }\n",
    "\n",
    "3. transition matrix is defined as $P(q_{t+1}|q_t)$: \\\n",
    "    Row: Hidden States [$q$], Column: Hidden States [$q$]\n",
    "4. emission matrix is defined as $P(S_j|q_i)$: \\\n",
    "    Row: Hidden States [$q$], Column: Observable States [$S$]\n",
    "\n",
    "#### Matrix plan v1\n",
    "Threshold variability\n",
    "\n",
    "#### Matrix plan v2\n",
    "Vary backtest period. Last 6 months? Last decade?\n",
    "\n",
    "#### Matrix plan v3\n",
    "Assume hidden states as a distribution\n",
    "\n",
    "#### Notes:\n",
    "1. Accuracy does not lead to better returns.\n",
    "2. Attempted Variational Inference model but couldn't get it to work reliably. I predict it could peprform better due to Bayesian Inference.\n",
    "\n",
    "#### Housekeeping\n",
    "I have:\n",
    "1. Created the transition matrix based on categorising trend data as \"Happy, Sad, Neutral\".\n",
    "\n",
    "2. Created the emission matrix based on \"Happy emitting Up\", etc.\n",
    "\n",
    "3. Set start matrix as arbitrary.\n",
    "\n",
    "4. Made a bunch of models to test parameters and versions\n",
    "\n",
    "5. Run simulation against test price data and keep track of profit as return %\n",
    "\n",
    "6. Create logger for results\n",
    "\n",
    "7. Results ran through certain parameters\n",
    "\n",
    "I need to:\n",
    "\n",
    "3. Structure document\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n",
      "/home/me/.local/lib/python3.11/site-packages/hmmlearn/utils.py:55: RuntimeWarning: invalid value encountered in subtract\n",
      "  a -= a_lse\n",
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned Transition Matrix:\n",
      "         Happy  Sad  Neutral\n",
      "Happy      NaN  NaN      NaN\n",
      "Sad        NaN  NaN      NaN\n",
      "Neutral    NaN  NaN      NaN\n",
      "Learned Emission Matrix:\n",
      "         Up  Down  Negligible Change\n",
      "Happy   NaN   NaN                NaN\n",
      "Sad     NaN   NaN                NaN\n",
      "Neutral NaN   NaN                NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/me/.local/lib/python3.11/site-packages/hmmlearn/utils.py:55: RuntimeWarning: invalid value encountered in subtract\n",
      "  a -= a_lse\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "startprob_ must sum to 1 (got nan)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[243], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtile(trainPrice, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m     43\u001b[0m MultiVitModel\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m---> 44\u001b[0m logprob, received \u001b[38;5;241m=\u001b[39m \u001b[43mMultiVitModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainPrice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Accuracy of most likely sequence of hidden states with respect to the trend data\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28msum\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m received_item, trainTrend_item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(received, trainTrend) \u001b[38;5;28;01mif\u001b[39;00m received_item \u001b[38;5;241m==\u001b[39m trainTrend_item)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(received))\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/hmmlearn/base.py:336\u001b[0m, in \u001b[0;36m_AbstractHMM.decode\u001b[0;34m(self, X, lengths, algorithm)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;124;03mFind most likely state sequence corresponding to ``X``.\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03mscore : Compute the log probability under the model.\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    335\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstartprob_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 336\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m algorithm \u001b[38;5;241m=\u001b[39m algorithm \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malgorithm\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m algorithm \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m DECODER_ALGORITHMS:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/hmmlearn/hmm.py:927\u001b[0m, in \u001b[0;36mMultinomialHMM._check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 927\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memissionprob_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_2d(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memissionprob_)\n\u001b[1;32m    929\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memissionprob_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/hmmlearn/base.py:971\u001b[0m, in \u001b[0;36mBaseHMM._check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstartprob_) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components:\n\u001b[1;32m    970\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstartprob_ must have length n_components\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 971\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_sum_1\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstartprob_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransmat_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransmat_)\n\u001b[1;32m    974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransmat_\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components):\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/hmmlearn/base.py:951\u001b[0m, in \u001b[0;36mBaseHMM._check_sum_1\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    949\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(s, \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 951\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    952\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must sum to 1 (got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    953\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m s\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    954\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m rows must sum to 1 (got row sums of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    955\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m s\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    956\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 1D or 2D array\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: startprob_ must sum to 1 (got nan)"
     ]
    }
   ],
   "source": [
    "## Model v1 - Forward-Backward Algorithm\n",
    "\n",
    "# Initialize the HMM model\n",
    "MultiMapModel = MultinomialHMM(n_components=n_hidden,init_params='',algorithm='map', random_state=SEED)\n",
    "\n",
    "# Set the model parameters\n",
    "MultiMapModel.n_features = n_obs\n",
    "MultiMapModel.startprob_ = start_matrix\n",
    "MultiMapModel.transmat_ = transition_matrix\n",
    "MultiMapModel.emissionprob_ = emission_matrix\n",
    "\n",
    "# Fit the model to the data\n",
    "X = np.tile(trainPrice, (3, 1)).T\n",
    "MultiMapModel.fit(X)\n",
    "logprob, received = MultiMapModel.decode(np.tile(trainPrice, (3, 1)).T)\n",
    "\n",
    "# Accuracy of most likely sequence of hidden states with respect to the trend data\n",
    "print(\"Accuracy: \", sum(1 for received_item, trainTrend_item in zip(received, trainTrend) if received_item == trainTrend_item)/len(received))\n",
    "\n",
    "# Pretty print the learned transition matrix\n",
    "print(\"Learned Transition Matrix:\")\n",
    "print(pd.DataFrame(MultiMapModel.transmat_, index=[\"Happy\", \"Sad\", \"Neutral\"], columns=[\"Happy\", \"Sad\", \"Neutral\"]))\n",
    "\n",
    "print(\"Learned Emission Matrix:\")\n",
    "print(pd.DataFrame(MultiMapModel.emissionprob_, index=[\"Happy\", \"Sad\", \"Neutral\"], columns=[\"Up\", \"Down\", \"Negligible Change\"]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Model v1 - Viterbi\n",
    "\n",
    "# Initialize the HMM model\n",
    "MultiVitModel = MultinomialHMM(n_components=n_hidden,init_params='',algorithm='viterbi', random_state=SEED)\n",
    "\n",
    "# Set the model parameters\n",
    "MultiVitModel.n_features = n_obs\n",
    "MultiVitModel.startprob_ = start_matrix\n",
    "MultiVitModel.transmat_ = transition_matrix\n",
    "MultiVitModel.emissionprob_ = emission_matrix\n",
    "\n",
    "# Fit the model to the data\n",
    "X = np.tile(trainPrice, (3, 1)).T\n",
    "MultiVitModel.fit(X)\n",
    "logprob, received = MultiVitModel.decode(np.tile(trainPrice, (3, 1)).T)\n",
    "\n",
    "# Accuracy of most likely sequence of hidden states with respect to the trend data\n",
    "print(\"Accuracy: \", sum(1 for received_item, trainTrend_item in zip(received, trainTrend) if received_item == trainTrend_item)/len(received))\n",
    "\n",
    "# Pretty print the learned transition matrix\n",
    "print(\"Learned Transition Matrix:\")\n",
    "print(pd.DataFrame(MultiVitModel.transmat_, index=[\"Happy\", \"Sad\", \"Neutral\"], columns=[\"Happy\", \"Sad\", \"Neutral\"]))\n",
    "\n",
    "print(\"Learned Emission Matrix:\")\n",
    "print(pd.DataFrame(MultiVitModel.emissionprob_, index=[\"Happy\", \"Sad\", \"Neutral\"], columns=[\"Up\", \"Down\", \"Negligible Change\"]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Model Empty\n",
    "\n",
    "MultiNullModel = MultinomialHMM(n_components=n_hidden,init_params='ste', random_state=SEED)\n",
    "\n",
    "X = np.tile(trainPrice, (3, 1)).T\n",
    "MultiNullModel.fit(X)\n",
    "logprob, received = MultiNullModel.decode(np.tile(trainPrice, (3, 1)).T)\n",
    "\n",
    "# Accuracy of most likely sequence of hidden states with respect to the trend data\n",
    "print(\"Accuracy: \", sum(1 for received_item, trainTrend_item in zip(received, trainTrend) if received_item == trainTrend_item)/len(received))\n",
    "\n",
    "# Pretty print the learned transition matrix\n",
    "print(\"Learned Transition Matrix:\")\n",
    "print(pd.DataFrame(MultiNullModel.transmat_, index=[\"Happy\", \"Sad\", \"Neutral\"], columns=[\"Happy\", \"Sad\", \"Neutral\"]))\n",
    "\n",
    "\n",
    "print(\"Learned Emission Matrix:\")\n",
    "print(pd.DataFrame(MultiNullModel.emissionprob_, index=[\"Happy\", \"Sad\", \"Neutral\"], columns=[\"Up\", \"Down\", \"Negligible Change\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Model v2 - Variational Inference Forward-Backward Algorithm\n",
    "\n",
    "# # Initialize the HMM model\n",
    "# VariMapModel = VariationalCategoricalHMM(n_components=n_hidden,init_params='',algorithm='map', random_state=SEED)\n",
    "\n",
    "# # Set the model parameters\n",
    "# VariMapModel.n_features = n_obs\n",
    "# VariMapModel.startprob_prior = start_matrix\n",
    "# VariMapModel.transmat_prior = transition_matrix\n",
    "# VariMapModel.emissionprob_prior = emission_matrix\n",
    "\n",
    "# # Fit the model to the data\n",
    "# X = np.tile(trainPrice, (1, 1))\n",
    "# VariMapModel.fit(X)\n",
    "# logprob, received = VariMapModel.decode(X)\n",
    "\n",
    "# # Accuracy of most likely sequence of hidden states with respect to the trend data\n",
    "# print(\"Accuracy: \", sum(1 for received_item, trainTrend_item in zip(received, trainTrend) if received_item == trainTrend_item)/len(received))\n",
    "\n",
    "# # Pretty print the learned transition matrix\n",
    "# print(\"Learned Transition Matrix:\")\n",
    "# print(pd.DataFrame(VariMapModel.transmat_, index=[\"Happy\", \"Sad\", \"Neutral\"], columns=[\"Happy\", \"Sad\", \"Neutral\"]))\n",
    "\n",
    "# print(\"Learned Emission Matrix:\")\n",
    "# print(pd.DataFrame(VariMapModel.emissionprob_, index=[\"Happy\", \"Sad\", \"Neutral\"], columns=[\"Up\", \"Down\", \"Negligible Change\"]))\n",
    "\n",
    "\n",
    "# ## Model v2 - Variational Inference Viterbi\n",
    "\n",
    "# # Initialize the HMM model\n",
    "# VariVitModel = VariationalCategoricalHMM(n_components=n_hidden,init_params='',algorithm='viterbi', random_state=SEED)\n",
    "\n",
    "# # Set the model parameters\n",
    "# VariVitModel.n_features = n_obs\n",
    "# VariVitModel.startprob_prior_ = start_matrix\n",
    "# VariVitModel.transmat_prior_ = transition_matrix\n",
    "# VariVitModel.emissionprob_prior_ = emission_matrix\n",
    "\n",
    "# # Fit the model to the data\n",
    "# X = np.array(trainPrice).reshape(-1, 1)\n",
    "# VariVitModel.fit(X)\n",
    "# logprob, received = VariVitModel.decode(X)\n",
    "\n",
    "# # Accuracy of most likely sequence of hidden states with respect to the trend data\n",
    "# print(\"Accuracy: \", sum(1 for received_item, trainTrend_item in zip(received, trainTrend) if received_item == trainTrend_item)/len(received))\n",
    "\n",
    "# # Pretty print the learned transition matrix\n",
    "# print(\"Learned Transition Matrix:\")\n",
    "# print(pd.DataFrame(VariVitModel.transmat_, index=[\"Happy\", \"Sad\", \"Neutral\"], columns=[\"Happy\", \"Sad\", \"Neutral\"]))\n",
    "\n",
    "# print(\"Learned Emission Matrix:\")\n",
    "# print(pd.DataFrame(VariVitModel.emissionprob_, index=[\"Happy\", \"Sad\", \"Neutral\"], columns=[\"Up\", \"Down\", \"Negligible Change\"]))\n",
    "\n",
    "\n",
    "# ## Model v2 - Variational Inference Null\n",
    "\n",
    "# # Initialize the HMM model\n",
    "# VariNullModel = VariationalCategoricalHMM(n_components=n_hidden,init_params='ste', random_state=SEED)\n",
    "\n",
    "# # Fit the model to the data\n",
    "# X = np.array(trainPrice).reshape(-1, 1)\n",
    "# VariNullModel.fit(X)\n",
    "# logprob, received = VariNullModel.decode(X)\n",
    "\n",
    "# # Accuracy of most likely sequence of hidden states with respect to the trend data\n",
    "# print(\"Accuracy: \", sum(1 for received_item, trainTrend_item in zip(received, trainTrend) if received_item == trainTrend_item)/len(received))\n",
    "\n",
    "# # Pretty print the learned transition matrix\n",
    "# print(\"Learned Transition Matrix:\")\n",
    "# print(pd.DataFrame(VariNullModel.transmat_, index=[\"Happy\", \"Sad\", \"Neutral\"], columns=[\"Happy\", \"Sad\", \"Neutral\"]))\n",
    "\n",
    "# print(\"Learned Emission Matrix:\")\n",
    "# print(pd.DataFrame(VariNullModel.emissionprob_, index=[\"Happy\", \"Sad\", \"Neutral\"], columns=[\"Up\", \"Down\", \"Negligible Change\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model Return on Investment:  -16.621427971616846\n",
      "Model v1 - Forward Backward Return on Investment:  16.621427971616846\n",
      "Model v2 - Viterbi Return on Investment:  16.621427971616846\n",
      "Multi Null Model Return on Investment:  44.364562413428644\n"
     ]
    }
   ],
   "source": [
    "## Predict the hidden states of the test data\n",
    "\n",
    "X_test = np.tile(discreteTestPrice, (3, 1)).T\n",
    "\n",
    "# Decode Multinomial models on Test data\n",
    "logprob, MultiMapModelreceived = MultiMapModel.decode(X_test)\n",
    "logprob, MultiVitModelreceived = MultiVitModel.decode(X_test)\n",
    "logprob, MultiNullmodelreceived = MultiNullModel.decode(X_test)\n",
    "\n",
    "# # Decode Variational models on Test data\n",
    "# logprob, VariMapModelreceived = VariMapModel.decode(X_test)\n",
    "# logprob, VariVitModelreceived = VariVitModel.decode(X_test)\n",
    "# logprob, VariNullModelreceived = VariNullModel.decode(X_test)\n",
    "\n",
    "test = pd.read_csv('OpenClosePrice.csv')\n",
    "testPrice = (test['Close'].values+test['Open'].values)/2\n",
    "testPrice = testPrice[start_time:stop_time]\n",
    "testPrice = testPrice[int(len(testPrice)*traintest_split):]\n",
    "\n",
    "# Buy or Sell or Hold based on the hidden states, calculate PnL based on the test price data\n",
    "MultiMap = [1000, 0] # cash in hand, position\n",
    "MultiVit = [1000, 0]\n",
    "MultiNull = [1000, 0]\n",
    "# VariMap = [1000, 0]\n",
    "# VariVit = [1000, 0]\n",
    "# VariNull = [1000, 0]\n",
    "BaseModel = [1000, 0]\n",
    "\n",
    "for i in range(len(testPrice)):\n",
    "    if i == 0:\n",
    "        BaseModel[0] -= testPrice[i]\n",
    "        BaseModel[1] += 1\n",
    "\n",
    "    # Multinomial Forward Backward Model\n",
    "    if MultiMapModelreceived[i] == 0:\n",
    "        MultiMap[0] -= testPrice[i]\n",
    "        MultiMap[1] += 1\n",
    "    elif MultiMapModelreceived[i] == 1:\n",
    "        MultiMap[0] += testPrice[i]\n",
    "        MultiMap[1] -= 1\n",
    "\n",
    "    # Multinomial Viterbi Model\n",
    "    if MultiVitModelreceived[i] == 0:\n",
    "        MultiVit[0] -= testPrice[i]\n",
    "        MultiVit[1] += 1\n",
    "    elif MultiVitModelreceived[i] == 1:\n",
    "        MultiVit[0] += testPrice[i]\n",
    "        MultiVit[1] -= 1\n",
    "\n",
    "        # Multinomial Null Model\n",
    "    if MultiNullmodelreceived[i] == 0:\n",
    "        MultiNull[0] -= testPrice[i]\n",
    "        MultiNull[1] += 1\n",
    "    elif MultiNullmodelreceived[i] == 1:\n",
    "        MultiNull[0] += testPrice[i]\n",
    "        MultiNull[1] -= 1\n",
    "\n",
    "\n",
    "    # # Variational Inference Forward Backward Model\n",
    "    # if VariMapModelreceived[i] == 0:\n",
    "    #     VariMap[0] -= testPrice[i]\n",
    "    #     VariMap[1] += 1\n",
    "    # elif VariMapModelreceived[i] == 1:\n",
    "    #     VariMap[0] += testPrice[i]\n",
    "    #     VariMap[1] -= 1\n",
    "\n",
    "    # # Variational Inference Viterbi Model\n",
    "    # if VariVitModelreceived[i] == 0:\n",
    "    #     VariVit[0] -= testPrice[i]\n",
    "    #     VariVit[1] += 1\n",
    "    # elif VariVitModelreceived[i] == 1:\n",
    "    #     VariVit[0] += testPrice[i]\n",
    "    #     VariVit[1] -= 1\n",
    "\n",
    "    # # Variational Inference Null Model\n",
    "    # if VariNullModelreceived[i] == 0:\n",
    "    #     VariNull[0] -= testPrice[i]\n",
    "    #     VariNull[1] += 1\n",
    "    # elif VariNullModelreceived[i] == 1:\n",
    "    #     VariNull[0] += testPrice[i]\n",
    "    #     VariNull[1] -= 1\n",
    "\n",
    "\n",
    "    if i == len(testPrice): # Exit position at the end\n",
    "        MultiMap[0] += MultiMap[1]*testPrice[i]\n",
    "        MultiMap[1] = 0\n",
    "        MultiVit[0] += MultiVit[1]*testPrice[i]\n",
    "        MultiVit[1] = 0\n",
    "        MultiNull[0] += MultiNull[1]*testPrice[i]\n",
    "        MultiNull[1] = 0\n",
    "        # VariMap[0] += VariMap[1]*testPrice[i]\n",
    "        # VariMap[1] = 0\n",
    "        # VariVit[0] += VariVit[1]*testPrice[i]\n",
    "        # VariVit[1] = 0\n",
    "        # VariNull[0] += VariNull[1]*testPrice[i]\n",
    "        # VariNull[1] = 0\n",
    "        BaseModel[0] += BaseModel[1]*testPrice[i]\n",
    "        BaseModel[1] = 0\n",
    "\n",
    "\n",
    "print(\"Base Model Return on Investment: \", (BaseModel[0]-1000)/10)\n",
    "print(\"Model v1 - Forward Backward Return on Investment: \", (MultiMap[0]-1000)/10)\n",
    "print(\"Model v2 - Viterbi Return on Investment: \", (MultiVit[0]-1000)/10)\n",
    "print(\"Multi Null Model Return on Investment: \", (MultiNull[0]-1000)/10)\n",
    "# print(\"Model v3 - Variational Inference Return on Investment: \", (VariMap[0]-1000)/10)\n",
    "# print(\"Model v4 - Variational Inference Viterbi Return on Investment: \", (VariVit[0]-1000)/10)\n",
    "# print(\"Vari Null Model Return on Investment: \", (VariNull[0]-1000)/10)\n",
    "\n",
    "\n",
    "# output is a list of return on investment calculations using lambda function\n",
    "output = [(x[0]-1000)/10 for x in [BaseModel, MultiMap, MultiVit, MultiNull]]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Logger\n",
    "\n",
    "with open('logs.csv', 'w') as f:\n",
    "    f.write(\"Model,Parameters,Return on Investment,\\n\") # Parameters contain backtest period, threshold\n",
    "    f.write(\"Base Strategy,{} months | {},{},\\n\".format(stop_time-start_time,threshold,output[0]))\n",
    "    f.write(\"Model v1,Forward-Backward Algorithm | {} months | {},{},\\n\".format(stop_time-start_time,threshold,output[1]))\n",
    "    f.write(\"Model v1,Viterbi Algorithm | {} months | {},{},\\n\".format(stop_time-start_time,threshold,output[2]))\n",
    "    f.write(\"Model v1,Null Model | {} months | {},{},\\n\".format(stop_time-start_time,threshold,output[3]))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
