{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hidden Markov Model\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from hmmlearn import hmm\n",
    "\n",
    "SEED = 42\n",
    "df = pd.read_csv('aggregated.csv')\n",
    "trend_data = df['nvidia'].values\n",
    "price_data = df['NVDA Monthly'].values\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct assumption Start Matrix\n",
    "\n",
    "states = ['Happy', 'Sad', 'Neutral']\n",
    "start_matrix = np.array([0.5, 0.3, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition Matrix:\n",
      "            Happy       Sad   Neutral\n",
      "Happy    0.225806  0.387097  0.387097\n",
      "Sad      0.531250  0.281250  0.187500\n",
      "Neutral  0.333333  0.523810  0.142857\n"
     ]
    }
   ],
   "source": [
    "# Constructing the Transition Matrix\n",
    "\n",
    "# row is t, column is t+1\n",
    "symbolVocabTrend = {0: \"Happy\", 1: \"Sad\", 2: \"Neutral\"}\n",
    "\n",
    "# Construct count of transitions from one hidden state to another i.e how many times 0 becomes 1, 1 becomes 2 etc.\n",
    "transition_counts = {}\n",
    "for i in range(1, len(trainTrend)):\n",
    "    transition = (symbolVocabTrend[discrete_trend_data[i-1]], symbolVocabTrend[discrete_trend_data[i]])\n",
    "    if transition not in transition_counts:\n",
    "        transition_counts[transition] = 0\n",
    "    transition_counts[transition] += 1\n",
    "\n",
    "# print(transition_counts)\n",
    "\n",
    "# Construct the transition matrix from the counts\n",
    "transition_matrix = np.zeros((n_hidden, n_hidden))\n",
    "for i in range(n_hidden):\n",
    "    for j in range(n_hidden):\n",
    "        transition = (symbolVocabTrend[i], symbolVocabTrend[j])\n",
    "        if transition in transition_counts:\n",
    "            transition_matrix[i, j] = transition_counts[transition] / sum([value for key, value in transition_counts.items() if key[0] == symbolVocabTrend[i]])\n",
    "\n",
    "# Pretty print the transition matrix with row and column labels\n",
    "print(\"Transition Matrix:\")\n",
    "print(pd.DataFrame(transition_matrix, index=[\"Happy\", \"Sad\", \"Neutral\"], columns=[\"Happy\", \"Sad\", \"Neutral\"]))\n",
    "\n",
    "### UNIT TESTING ###\n",
    "\n",
    "# Test the transition matrix\n",
    "assert np.allclose(transition_matrix.sum(axis=1), np.ones(n_hidden)), \"Transition matrix rows should sum to 1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emission Matrix:\n",
      "               Up      Down  Negligible Change\n",
      "Happy    0.580645  0.193548           0.225806\n",
      "Sad      0.656250  0.250000           0.093750\n",
      "Neutral  0.636364  0.227273           0.136364\n"
     ]
    }
   ],
   "source": [
    "# Building Price Emission Matrix\n",
    "\n",
    "# row is emitting column\n",
    "symbolVocabPrice = {0: \"Up\", 1: \"Down\", 2: \"Negligible Change\"}\n",
    "\n",
    "# Building Price Emission Matrix\n",
    "\n",
    "price_symbol_counts = {}\n",
    "\n",
    "# Iterate over the time series data of trend and price data along with the corresponding hidden states\n",
    "for trendState, priceAction in zip(trainTrend, trainPrice):\n",
    "    # Update symbol counts for price data\n",
    "    emission = (symbolVocabTrend[trendState], symbolVocabPrice[priceAction])\n",
    "    if emission not in price_symbol_counts:\n",
    "        price_symbol_counts[emission] = 0\n",
    "    price_symbol_counts[emission] += 1\n",
    "\n",
    "# print(price_symbol_counts)\n",
    "\n",
    "# Construct the emission matrix from the counts\n",
    "emission_matrix = np.zeros((n_hidden, n_obs))\n",
    "for i in range(n_hidden):\n",
    "    for j in range(n_obs):\n",
    "        emission = (symbolVocabTrend[i], symbolVocabPrice[j])\n",
    "        if emission in price_symbol_counts:\n",
    "            emission_matrix[i, j] = price_symbol_counts[emission] / sum([value for key, value in price_symbol_counts.items() if key[0] == symbolVocabTrend[i]])\n",
    "\n",
    "# Pretty print the emission matrix with row and column labels\n",
    "print(\"Emission Matrix:\")\n",
    "print(pd.DataFrame(emission_matrix, index=[\"Happy\", \"Sad\", \"Neutral\"], columns=[\"Up\", \"Down\", \"Negligible Change\"]))\n",
    "\n",
    "### UNIT TESTING ###\n",
    "\n",
    "# Test the emission matrix\n",
    "assert np.allclose(emission_matrix.sum(axis=1), np.ones(n_hidden)), \"Emission matrix rows should sum to 1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Markov Model\n",
    "Using Viterbi and Forward-Backward to decide states, we draft our plan as such: \\\n",
    "\n",
    "\n",
    "\n",
    "1. q_state = 3 { Happy, Sad, Neutral }\n",
    "\n",
    "2. obs_states = { Up, Down, Negligible Change }\n",
    "\n",
    "3. transition matrix is defined as $P(q_{t+1}|q_t)$: \\\n",
    "    Row: Hidden States [$q$], Column: Hidden States [$q$]\n",
    "4. emission matrix is defined as $P(S_j|q_i)$: \\\n",
    "    Row: Hidden States [$q$], Column: Observable States [$S$]\n",
    "    \n",
    "\n",
    "#### Matrix plan v1\n",
    "Threshold variability\n",
    "\n",
    "\n",
    "#### Matrix plan v2\n",
    "Assume hidden states as a distribution\n",
    "\n",
    "#### Matrix plan v3\n",
    "Vary backtest period. Last 6 months? Last decade?\n",
    "\n",
    "#### Notes:\n",
    "1. Accuracy does not lead to better returns.\n",
    "\n",
    "#### Housekeeping\n",
    "I have:\n",
    "1. Created the transition matrix based on categorising trend data as \"Happy, Sad, Neutral\".\n",
    "\n",
    "2. Created the emission matrix based on \"Happy emitting Up\", etc.\n",
    "\n",
    "3. Set start matrix as arbitrary.\n",
    "\n",
    "4. Made a bunch of models to test parameters and versions\n",
    "\n",
    "5. Run simulation against test price data and keep track of profit as return %\n",
    "\n",
    "6. Create logger for results\n",
    "\n",
    "I need to:\n",
    "1. Do more tests\n",
    "\n",
    "2. Try VariationalCategoricalHMM\n",
    "\n",
    "3. Structure document\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 3 # states: happy, sad, neutral\n",
    "n_obs = 3 # observations: up, down, negligible change\n",
    "traintest_split = 0.7\n",
    "threshold = 0.02\n",
    "start_time, stop_time = 110, 232 # length of data: 242\n",
    "\n",
    "trend_data = trend_data[start_time:stop_time]\n",
    "price_data = price_data[start_time:stop_time]\n",
    "\n",
    "## Trend data: 0 - Happy, 1 - Sad, 2 - Neutral\n",
    "discrete_trend_data = [0 if x >= threshold else 1 if x <= -threshold else 2 for x in trend_data]\n",
    "## Price data: 0 - Up, 1 - Down, 2 - Negligible change\n",
    "discrete_price_data = [0 if x >= threshold else 1 if x <= -threshold else 2 for x in price_data]\n",
    "\n",
    "# Test and Train data\n",
    "trainTrend, testTrend = discrete_trend_data[:int(len(trend_data)*traintest_split)], discrete_trend_data[int(len(trend_data)*traintest_split):]\n",
    "trainPrice, discreteTestPrice = discrete_price_data[:int(len(price_data)*traintest_split)], discrete_price_data[int(len(price_data)*traintest_split):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.36470588235294116\n",
      "Learned Transition Matrix:\n",
      "            Happy       Sad   Neutral\n",
      "Happy    0.260757  0.354676  0.384567\n",
      "Sad      0.573801  0.248974  0.177224\n",
      "Neutral  0.377774  0.481391  0.140835\n",
      "Learned Emission Matrix:\n",
      "               Up      Down  Negligible Change\n",
      "Happy    0.333333  0.333333           0.333333\n",
      "Sad      0.333333  0.333333           0.333333\n",
      "Neutral  0.333333  0.333333           0.333333\n"
     ]
    }
   ],
   "source": [
    "## Model v1 - Forward-Backward Algorithm\n",
    "\n",
    "# Initialize the HMM model\n",
    "modelv1 = hmm.MultinomialHMM(n_components=n_hidden,init_params='',algorithm='map', random_state=SEED)\n",
    "\n",
    "# Set the model parameters\n",
    "modelv1.n_features = n_obs\n",
    "modelv1.startprob_ = start_matrix\n",
    "modelv1.transmat_ = transition_matrix\n",
    "modelv1.emissionprob_ = emission_matrix\n",
    "\n",
    "# Fit the model to the data\n",
    "X = np.tile(trainPrice, (3, 1)).T\n",
    "modelv1.fit(X)\n",
    "logprob, received = modelv1.decode(np.tile(trainPrice, (3, 1)).T)\n",
    "\n",
    "# Accuracy of most likely sequence of hidden states with respect to the trend data\n",
    "print(\"Accuracy: \", sum(1 for received_item, trainTrend_item in zip(received, trainTrend) if received_item == trainTrend_item)/len(received))\n",
    "\n",
    "# Pretty print the learned transition matrix\n",
    "print(\"Learned Transition Matrix:\")\n",
    "print(pd.DataFrame(modelv1.transmat_, index=[\"Happy\", \"Sad\", \"Neutral\"], columns=[\"Happy\", \"Sad\", \"Neutral\"]))\n",
    "\n",
    "print(\"Learned Emission Matrix:\")\n",
    "print(pd.DataFrame(modelv1.emissionprob_, index=[\"Happy\", \"Sad\", \"Neutral\"], columns=[\"Up\", \"Down\", \"Negligible Change\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.2235294117647059\n",
      "Learned Transition Matrix:\n",
      "            Happy       Sad   Neutral\n",
      "Happy    0.260757  0.354676  0.384567\n",
      "Sad      0.573801  0.248974  0.177224\n",
      "Neutral  0.377774  0.481391  0.140835\n",
      "Learned Emission Matrix:\n",
      "               Up      Down  Negligible Change\n",
      "Happy    0.333333  0.333333           0.333333\n",
      "Sad      0.333333  0.333333           0.333333\n",
      "Neutral  0.333333  0.333333           0.333333\n"
     ]
    }
   ],
   "source": [
    "## Model v2 - Viterbi\n",
    "\n",
    "# Initialize the HMM model\n",
    "modelv2 = hmm.MultinomialHMM(n_components=n_hidden,init_params='',algorithm='viterbi', random_state=SEED)\n",
    "\n",
    "# Set the model parameters\n",
    "modelv2.n_features = n_obs\n",
    "modelv2.startprob_ = start_matrix\n",
    "modelv2.transmat_ = transition_matrix\n",
    "modelv2.emissionprob_ = emission_matrix\n",
    "\n",
    "# Fit the model to the data\n",
    "X = np.tile(trainPrice, (3, 1)).T\n",
    "modelv2.fit(X)\n",
    "logprob, received = modelv2.decode(np.tile(trainPrice, (3, 1)).T)\n",
    "\n",
    "# Accuracy of most likely sequence of hidden states with respect to the trend data\n",
    "print(\"Accuracy: \", sum(1 for received_item, trainTrend_item in zip(received, trainTrend) if received_item == trainTrend_item)/len(received))\n",
    "\n",
    "# Pretty print the learned transition matrix\n",
    "print(\"Learned Transition Matrix:\")\n",
    "print(pd.DataFrame(modelv2.transmat_, index=[\"Happy\", \"Sad\", \"Neutral\"], columns=[\"Happy\", \"Sad\", \"Neutral\"]))\n",
    "\n",
    "print(\"Learned Emission Matrix:\")\n",
    "print(pd.DataFrame(modelv2.emissionprob_, index=[\"Happy\", \"Sad\", \"Neutral\"], columns=[\"Up\", \"Down\", \"Negligible Change\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.25882352941176473\n",
      "Learned Transition Matrix:\n",
      "            Happy       Sad   Neutral\n",
      "Happy    0.001151  0.998823  0.000026\n",
      "Sad      0.968256  0.007915  0.023830\n",
      "Neutral  0.497101  0.138508  0.364391\n",
      "Learned Emission Matrix:\n",
      "               Up      Down  Negligible Change\n",
      "Happy    0.333333  0.333333           0.333333\n",
      "Sad      0.333333  0.333333           0.333333\n",
      "Neutral  0.333333  0.333333           0.333333\n"
     ]
    }
   ],
   "source": [
    "## Model Empty\n",
    "new_model = hmm.MultinomialHMM(n_components=n_hidden,init_params='ste', random_state=SEED)\n",
    "\n",
    "new_model.fit(X)\n",
    "logprob, received = new_model.decode(np.tile(trainPrice, (3, 1)).T)\n",
    "\n",
    "# Accuracy of most likely sequence of hidden states with respect to the trend data\n",
    "print(\"Accuracy: \", sum(1 for received_item, trainTrend_item in zip(received, trainTrend) if received_item == trainTrend_item)/len(received))\n",
    "\n",
    "# Pretty print the learned transition matrix\n",
    "print(\"Learned Transition Matrix:\")\n",
    "print(pd.DataFrame(new_model.transmat_, index=[\"Happy\", \"Sad\", \"Neutral\"], columns=[\"Happy\", \"Sad\", \"Neutral\"]))\n",
    "\n",
    "\n",
    "print(\"Learned Emission Matrix:\")\n",
    "print(pd.DataFrame(new_model.emissionprob_, index=[\"Happy\", \"Sad\", \"Neutral\"], columns=[\"Up\", \"Down\", \"Negligible Change\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model v3 - Variational Inference\n",
    "\n",
    "# Initialize the HMM model\n",
    "modelv3 = hmm.VariationalCategoricalHMM(n_components=n_hidden,init_params='',algorithm='map', random_state=SEED)\n",
    "\n",
    "# Set the model parameters\n",
    "modelv3.n_features = n_obs\n",
    "modelv3.startprob_ = start_matrix\n",
    "modelv3.transmat_ = transition_matrix\n",
    "modelv3.emissionprob_ = emission_matrix\n",
    "\n",
    "# Fit the model to the data\n",
    "X = np.tile(trainPrice, (3, 1)).T\n",
    "modelv3.fit(X)\n",
    "logprob, received = modelv3.decode(np.tile(trainPrice, (3, 1)).T)\n",
    "\n",
    "# Accuracy of most likely sequence of hidden states with respect to the trend data\n",
    "print(\"Accuracy: \", sum(1 for received_item, trainTrend_item in zip(received, trainTrend) if received_item == trainTrend_item)/len(received))\n",
    "\n",
    "# Pretty print the learned transition matrix\n",
    "print(\"Learned Transition Matrix:\")\n",
    "print(pd.DataFrame(modelv3.transmat_, index=[\"Happy\", \"Sad\", \"Neutral\"], columns=[\"Happy\", \"Sad\", \"Neutral\"]))\n",
    "\n",
    "print(\"Learned Emission Matrix:\")\n",
    "print(pd.DataFrame(modelv3.emissionprob_, index=[\"Happy\", \"Sad\", \"Neutral\"], columns=[\"Up\", \"Down\", \"Negligible Change\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model v1 - Forward Backward Return on Investment:  -650.7733773362582\n",
      "Model v2 - Viterbi Return on Investment:  -6.950748872047598\n",
      "Null Model Return on Investment:  18.085689243641173\n",
      "Base Model Return on Investment:  -6.826545745829094\n"
     ]
    }
   ],
   "source": [
    "# Predict the hidden states of the test data\n",
    "X_test = np.tile(discreteTestPrice, (3, 1)).T\n",
    "\n",
    "logprob, modelv1received = modelv1.decode(X_test)\n",
    "logprob, modelv2received = modelv2.decode(X_test)\n",
    "logprob, nullmodelreceived = new_model.decode(X_test)\n",
    "\n",
    "test = pd.read_csv('OpenClosePrice.csv')\n",
    "testPrice = (test['Close'].values+test['Open'].values)/2\n",
    "testPrice = testPrice[start_time:stop_time]\n",
    "testPrice = testPrice[int(len(testPrice)*traintest_split):]\n",
    "\n",
    "# Buy or Sell or Hold based on the hidden states, calculate PnL based on the test price data\n",
    "currA = [1000, 0] # cash in hand, position\n",
    "currB = [1000, 0]\n",
    "currC = [1000, 0]\n",
    "currBase = [1000, 0]\n",
    "\n",
    "for i in range(len(testPrice)):\n",
    "    if i == 0:\n",
    "        currBase[0] -= testPrice[i]\n",
    "        currBase[1] += 1\n",
    "\n",
    "    # Model v1\n",
    "    if modelv1received[i] == 0:\n",
    "        currA[0] -= testPrice[i]\n",
    "        currA[1] += 1\n",
    "    elif modelv1received[i] == 1:\n",
    "        currA[0] += testPrice[i]\n",
    "        currA[1] -= 1\n",
    "\n",
    "    # Model v2\n",
    "    if modelv2received[i] == 0:\n",
    "        currB[0] -= testPrice[i]\n",
    "        currB[1] += 1\n",
    "    elif modelv2received[i] == 1:\n",
    "        currB[0] += testPrice[i]\n",
    "        currB[1] -= 1\n",
    "\n",
    "    # Null Model\n",
    "    if nullmodelreceived[i] == 0:\n",
    "        currC[0] -= testPrice[i]\n",
    "        currC[1] += 1\n",
    "    elif nullmodelreceived[i] == 1:\n",
    "        currC[0] += testPrice[i]\n",
    "        currC[1] -= 1\n",
    "\n",
    "    if i == len(testPrice): # Exit position at the end\n",
    "        currA[0] += currA[1]*testPrice[i]\n",
    "        currA[1] = 0\n",
    "        currB[0] += currB[1]*testPrice[i]\n",
    "        currB[1] = 0\n",
    "        currC[0] += currC[1]*testPrice[i]\n",
    "        currC[1] = 0\n",
    "        currBase[0] += currBase[1]*testPrice[i]\n",
    "        currBase[1] = 0\n",
    "\n",
    "print(\"Model v1 - Forward Backward Return on Investment: \", (currA[0]-1000)/10)\n",
    "print(\"Model v2 - Viterbi Return on Investment: \", (currB[0]-1000)/10)\n",
    "print(\"Null Model Return on Investment: \", (currC[0]-1000)/10)\n",
    "print(\"Base Model Return on Investment: \", (currBase[0]-1000)/10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Logger\n",
    "\n",
    "with open('logs.csv', 'w') as f:\n",
    "    f.write(\"Model,Parameters,Return on Investment,\\n\") # Parameters contain backtest period, threshold\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
